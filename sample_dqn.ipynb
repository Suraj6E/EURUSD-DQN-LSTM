{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Deep Q-Network Leanring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define the Deep Q-Network (DQN) architecture\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x.view(x.size(0), -1)  # Reshape output to have shape [batch_size, num_actions]\n",
    "\n",
    "\n",
    "# Define the Deep Q-Learning agent\n",
    "class DQNAgent:\n",
    "    def __init__(self, input_size, output_size, learning_rate=0.001, gamma=0.99, epsilon=1.0, epsilon_decay=0.999, epsilon_min=0.01):\n",
    "        # self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.device = torch.device(\"cpu\")\n",
    "        self.q_network = DQN(input_size, output_size).to(self.device)\n",
    "        self.target_network = DQN(input_size, output_size).to(self.device)\n",
    "        self.target_network.load_state_dict(self.q_network.state_dict())\n",
    "        self.target_network.eval()\n",
    "        self.optimizer = optim.Adam(self.q_network.parameters(), lr=learning_rate)\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return random.randrange(self.output_size)  # Choose a random action\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state_tensor = torch.FloatTensor(state).to(self.device)\n",
    "                q_values = self.q_network(state_tensor)\n",
    "                return torch.argmax(q_values).item()  # Choose action with highest Q-value\n",
    "\n",
    "    def train(self, state, action, next_state, reward, done):\n",
    "        state_tensor = torch.FloatTensor(state).to(self.device)\n",
    "        next_state_tensor = torch.FloatTensor(next_state).to(self.device)\n",
    "        action_tensor = torch.LongTensor([action]).to(self.device)\n",
    "        reward_tensor = torch.FloatTensor([reward]).to(self.device)\n",
    "        done_tensor = torch.FloatTensor([done]).to(self.device)\n",
    "\n",
    "        # Calculate Q-values for current and next states\n",
    "        q_values = self.q_network(state_tensor)\n",
    "        next_q_values = self.target_network(next_state_tensor)\n",
    "        print(f\"Q-values shape: {q_values.shape}\")\n",
    "        print(f\"Next Q-values shape: {next_q_values.shape}\")\n",
    "\n",
    "        q_value = q_values.gather(1, action_tensor.unsqueeze(1)).squeeze(1)\n",
    "        print(f\"Q-value shape: {q_value.shape}\")\n",
    "\n",
    "        # Calculate target Q-value using the Bellman equation\n",
    "        target_q = reward_tensor + (1 - done_tensor) * self.gamma * next_q_values.max(1)[0]\n",
    "        print(f\"Target Q-value shape: {target_q.shape}\")\n",
    "\n",
    "        # Calculate loss and update Q-network\n",
    "        loss = self.loss_function(q_value, target_q.detach())\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Decay epsilon\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Define the environment\n",
    "class GridWorld:\n",
    "    def __init__(self, grid_size=5, num_obstacles=5):\n",
    "        self.grid_size = grid_size\n",
    "        self.num_obstacles = num_obstacles\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.agent_position = torch.tensor([0, 0], dtype=torch.float32)\n",
    "        self.goal_position = torch.tensor([self.grid_size - 1, self.grid_size - 1], dtype=torch.float32)\n",
    "        self.obstacle_positions = {(torch.randint(0, self.grid_size, (1,)).item(), torch.randint(0, self.grid_size, (1,)).item()) for _ in range(self.num_obstacles)}\n",
    "        self.done = False\n",
    "        \n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            raise ValueError(\"Episode has ended, please call reset() to restart.\")\n",
    "\n",
    "        if action == 0:  # Move right\n",
    "            next_position = (self.agent_position[0], min(self.grid_size - 1, self.agent_position[1] + 1))\n",
    "        elif action == 1:  # Move left\n",
    "            next_position = (self.agent_position[0], max(0, self.agent_position[1] - 1))\n",
    "        elif action == 2:  # Move down\n",
    "            next_position = (min(self.grid_size - 1, self.agent_position[0] + 1), self.agent_position[1])\n",
    "        elif action == 3:  # Move up\n",
    "            next_position = (max(0, self.agent_position[0] - 1), self.agent_position[1])\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action.\")\n",
    "\n",
    "        next_position = tuple(next_position)  # Convert to tuple\n",
    "        next_state = self.render()  # Get the entire grid state\n",
    "        if next_position in self.obstacle_positions:\n",
    "            reward = torch.tensor(-1, dtype=torch.float32)\n",
    "        elif torch.all(torch.tensor(next_position) == self.goal_position):\n",
    "            reward = torch.tensor(1, dtype=torch.float32)\n",
    "            self.done = True\n",
    "        else:\n",
    "            reward = torch.tensor(0, dtype=torch.float32)\n",
    "\n",
    "        self.agent_position = torch.tensor(next_position)\n",
    "\n",
    "        return next_state, reward, self.done\n",
    "\n",
    "    def render(self):\n",
    "        grid = torch.zeros((self.grid_size, self.grid_size))\n",
    "        agent_row, agent_col = self.agent_position.long().tolist()  # Convert to integers\n",
    "        grid[agent_row, agent_col] = 0.5  # Agent position\n",
    "        goal_row, goal_col = self.goal_position.long().tolist()  # Convert to integers\n",
    "        grid[goal_row, goal_col] = 0.8  # Goal position\n",
    "        for obstacle_pos in self.obstacle_positions:\n",
    "            obstacle_row, obstacle_col = obstacle_pos\n",
    "            grid[obstacle_row, obstacle_col] = 0.2  # Obstacle position\n",
    "        return grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running above environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next state tensor shape: torch.Size([1, 25])\n",
      "Next state flattened: [0.5, 0.0, 0.0, 0.20000000298023224, 0.0, 0.0, 0.20000000298023224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000000298023224, 0.0, 0.0, 0.0, 0.20000000298023224, 0.0, 0.0, 0.20000000298023224, 0.0, 0.0, 0.800000011920929]\n",
      "Environment grid size: 5\n",
      "Q-values shape: torch.Size([4, 1])\n",
      "Next Q-values shape: torch.Size([4, 1])\n",
      "Q-value shape: torch.Size([1])\n",
      "Target Q-value shape: torch.Size([4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNext state flattened: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_state_flat\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Print the flattened next state\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnvironment grid size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mgrid_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Print the grid size of the environment\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_state_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pass the flattened next state to the agent\u001b[39;00m\n\u001b[0;32m     25\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state_flat\n\u001b[0;32m     26\u001b[0m step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[27], line 72\u001b[0m, in \u001b[0;36mDQNAgent.train\u001b[1;34m(self, state, action, next_state, reward, done)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     71\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 72\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Decay epsilon\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_min:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;129m@_use_grad_for_differentiable\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    135\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform a single optimization step.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m            and returns the loss.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_graph_capture_health_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:333\u001b[0m, in \u001b[0;36mOptimizer._cuda_graph_capture_health_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_graph_capture_health_check\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;66;03m# Note [torch.compile x capturable]\u001b[39;00m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001b[39;00m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001b[39;00m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_built() \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m--> 333\u001b[0m         capturing \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_current_stream_capturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m capturing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups):\n\u001b[0;32m    336\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    337\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    338\u001b[0m                                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but param_groups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m capturable is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ACER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\cuda\\graphs.py:27\u001b[0m, in \u001b[0;36mis_current_stream_capturing\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_current_stream_capturing\u001b[39m():\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cuda_isCurrentStreamCapturing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Training loop\n",
    "env = GridWorld(grid_size=5, num_obstacles=5)\n",
    "input_size = env.grid_size * env.grid_size  # Flatten the grid\n",
    "output_size = 4  # Number of possible actions (right, left, down, up)\n",
    "agent = DQNAgent(input_size, output_size)\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    env.reset()\n",
    "    done = False\n",
    "    step_count = 0\n",
    "    state = env.render().flatten().tolist()\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.select_action(state)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        next_state_flat = np.ravel(next_state).tolist()  # Flatten the next state\n",
    "        next_state_tensor = torch.FloatTensor(next_state_flat).unsqueeze(0)  # Convert to tensor and add batch dimension\n",
    "        print(f\"Next state tensor shape: {next_state_tensor.shape}\")  # Print the shape of next_state_tensor\n",
    "        print(f\"Next state flattened: {next_state_flat}\")  # Print the flattened next state\n",
    "        print(f\"Environment grid size: {env.grid_size}\")  # Print the grid size of the environment\n",
    "        agent.train(state, action, next_state_flat, reward, done)  # Pass the flattened next state to the agent\n",
    "        state = next_state_flat\n",
    "        step_count += 1\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}: Total Steps = {step_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Found 1 GPU(s):\n",
      "  - GPU 0: NVIDIA GeForce GTX 1660 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. Found {torch.cuda.device_count()} GPU(s):\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  - GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
